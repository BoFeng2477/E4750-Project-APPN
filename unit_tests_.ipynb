{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf858571-dad5-4fb1-b919-1eee1ed0742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from SparsityAnalysis import extract_patterns, SparseConvArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3631530-d3e9-4c5a-9193-9a14b6a5d29f",
   "metadata": {},
   "source": [
    "### A Simple Demo Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aceee98-1132-49a2-a890-6eeb34749ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = np.array(\n",
    "        [[[[0., 0., 0.],\n",
    "           [0., 1., 0.],\n",
    "           [1., 1., 1.]],\n",
    "\n",
    "          [[0., 0., 0.],\n",
    "           [0., 1., 0.],\n",
    "           [1., 1., 1.]],\n",
    "\n",
    "          [[0., 0., 0.],\n",
    "           [0., 1., 0.],\n",
    "           [1., 1., 1.]]]])\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a6f8f27-af44-478c-8f4e-bb34a07fb964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns = np.array(extract_patterns(weight))\n",
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "952223b6-5930-47ae-9d32-f034d8593686",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_conv_arrays = SparseConvArrays(weight, patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8edf408-a172-43ea-a49e-5dc1419fdd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset:[0 3]\n",
      "\n",
      "reorder:[0]\n",
      "\n",
      "index:[0 1 2]\n",
      "\n",
      "stride:[0 3]\n",
      "\n",
      "weight:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "ptset:\n",
      "[[[1 1]\n",
      "  [2 0]\n",
      "  [2 1]\n",
      "  [2 2]]]\n"
     ]
    }
   ],
   "source": [
    "offset = sparse_conv_arrays.offset\n",
    "reorder = sparse_conv_arrays.reorder\n",
    "index = sparse_conv_arrays.index\n",
    "stride = sparse_conv_arrays.stride\n",
    "weight = sparse_conv_arrays.weight\n",
    "ptset = sparse_conv_arrays.ptset\n",
    "print(f\"offset:{offset}\\n\\nreorder:{reorder}\\n\\nindex:{index}\\n\\nstride:{stride}\\n\\nweight:{weight}\\n\\nptset:\\n{ptset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b8c2d3-3c2b-4d03-87e5-90f7872b1320",
   "metadata": {},
   "source": [
    "### Load Actual Weights from Pattern-Pruned ResNet-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8878e4f-f2c7-48de-9153-a2b1bfa3054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'resnet34_6_pattern_connectivity_pruning.pt'\n",
    "state_dict = torch.load(path, map_location=torch.device('cpu'))\n",
    "\n",
    "# residual_conv_dict = {k:v.cpu().numpy() for (k,v) in state_dict.items() if \"layer\" in k and \"conv\" in k}\n",
    "residual_convs = [v.cpu().numpy() for (k, v) in state_dict.items() if \"layer\" in k and \"conv\" in k]\n",
    "data_shapes = [\n",
    "    [1, 64, 32, 32], [1, 64, 32, 32], [1, 64, 32, 32], [1, 64, 32, 32], [1, 64, 32, 32], [1, 64, 32, 32],\n",
    "    [1, 64, 32, 32], [1, 128, 16, 16], [1, 128, 16, 16], [1, 128, 16, 16], [1, 128, 16, 16], [1, 128, 16, 16],\n",
    "    [1, 128, 16, 16], [1, 128, 16, 16], [1, 128, 16, 16], [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8],\n",
    "    [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8],\n",
    "    [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8], [1, 512, 4, 4], [1, 512, 4, 4], [1, 512, 4, 4],\n",
    "    [1, 512, 4, 4], [1, 512, 4, 4],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c8dff",
   "metadata": {},
   "source": [
    "### Correctness Check - unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e68d6537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_cuda|nnpack: True\n"
     ]
    }
   ],
   "source": [
    "from conv_naive import Convolution\n",
    "conv = Convolution()\n",
    "ip = np.ones((1,64,32,32)).astype(np.float32)\n",
    "mask = np.ones((128,64,3,3)).astype(np.float32)\n",
    "output_1,_ = conv.conv_multiple_filters(ip, mask)\n",
    "output_gt = nn.functional.conv2d(torch.tensor(ip), torch.tensor(mask),padding=1)\n",
    "output_gt = output_gt.cpu().numpy()\n",
    "# print(output_gt)\n",
    "# print(output_1)\n",
    "print(f'conv_cuda|nnpack: {np.allclose(output_1,output_gt)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7839de4",
   "metadata": {},
   "source": [
    "### Correctness Check - full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "555a4cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-14950.9375\n",
      "********** conv layer 0 **********\n",
      "conv_cuda|nnpack: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from conv_naive import Convolution\n",
    "import numpy as np\n",
    "conv = Convolution()\n",
    "for idx in range(len(residual_convs[:1])):\n",
    "    input_data = np.ones(data_shapes[idx]).astype(np.float32)\n",
    "    conv_mask = residual_convs[idx].astype(np.float32)\n",
    "    output_1, _ = conv.conv_multiple_filters(input_data, conv_mask)\n",
    "    output_gt = nn.functional.conv2d(torch.tensor(input_data), torch.tensor(conv_mask),padding=1)\n",
    "    output_gt = output_gt.cpu().numpy()\n",
    "    print(np.sum(output_1))\n",
    "    print(np.sum(output_gt))\n",
    "    print('*'*10 + f' conv layer {idx} ' + '*'*10)\n",
    "    print(f'conv_cuda|nnpack: {np.allclose(output_1,output_gt,rtol=1e-5)}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a672c8",
   "metadata": {},
   "source": [
    "### Time Cost w/o memory transfer - nnpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ef6fed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d25d0a1e3f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcuda0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from conv_naive import Convolution\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "conv = Convolution()\n",
    "cuda0 = torch.device('cuda:0')\n",
    "cpu = torch.device('cpu')\n",
    "total_time = 0\n",
    "output_time_nnpack = []\n",
    "\n",
    "\n",
    "for idx in tqdm(range(len(residual_convs[:]))):\n",
    "    input_data = np.ones(data_shapes[idx]).astype(np.float32)\n",
    "    conv_mask = residual_convs[idx].astype(np.float32)\n",
    "    input_data_g = torch.tensor(input_data, device = cuda0)\n",
    "    conv_mask_g = torch.tensor(conv_mask, device = cuda0)\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    output_gt = nn.functional.conv2d(input_data_g, conv_mask_g,padding=1)\n",
    "    #output_gt = nn.functional.conv2d(torch.tensor(input_data), torch.tensor(conv_mask),padding=1)\n",
    "    torch.cuda.synchronize()\n",
    "    end =  time.time()\n",
    "    total_time += end - start\n",
    "    output_time_nnpack.append(end - start)\n",
    "\n",
    "\n",
    "print(f'{round(total_time,3)}s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e77bc8",
   "metadata": {},
   "source": [
    "### Time Cost w/o memory transfer - conv_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fb0579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 235.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08982825589179994\n",
      "[0.0024256000518798827, 0.0022520639896392823, 0.0024153919219970705, 0.002389663934707642, 0.0023896000385284426, 0.0024553918838500976, 0.004481056213378906, 0.002386176109313965, 0.002385215997695923, 0.0023887999057769778, 0.0023819200992584227, 0.002382528066635132, 0.0023797760009765627, 0.0023854079246520997, 0.004687488079071045, 0.0021965761184692383, 0.0021887359619140625, 0.002189568042755127, 0.0021876800060272217, 0.002187295913696289, 0.0021900479793548586, 0.002189568042755127, 0.0021905601024627686, 0.002204416036605835, 0.0021965439319610596, 0.0021927359104156495, 0.00426262378692627, 0.00425276803970337, 0.004253759860992432, 0.004253727912902832, 0.00425161600112915, 0.004253952026367187]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from conv_naive import Convolution\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "conv = Convolution()\n",
    "cuda0 = torch.device('cuda:0')\n",
    "total_time = 0\n",
    "output_list = []\n",
    "\n",
    "for idx in tqdm(range(len(residual_convs[:]))):\n",
    "    input_data = np.ones(data_shapes[idx]).astype(np.float32)\n",
    "    conv_mask = residual_convs[idx].astype(np.float32)\n",
    "    output_1, time_= conv.conv_multiple_filters(input_data, conv_mask)\n",
    "    output_list.append(time_)\n",
    "    total_time += time_\n",
    "\n",
    "print(total_time)\n",
    "print(output_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb04872",
   "metadata": {},
   "source": [
    "### Space Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e374e7f-3f55-4b54-9f34-76cc26eb1173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** conv layer 0 **********\n",
      "Normal_conv_mask:\n",
      "147456\n",
      "FKW_conv_mask:\n",
      "6600\n",
      "\n",
      "********** conv layer 1 **********\n",
      "Normal_conv_mask:\n",
      "147456\n",
      "FKW_conv_mask:\n",
      "6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(residual_convs[-3:-1])):\n",
    "    patterns = np.array(extract_patterns(residual_convs[idx]))\n",
    "    sparse_conv_arrays = SparseConvArrays(residual_convs[idx], patterns)\n",
    "    offset = sparse_conv_arrays.offset\n",
    "    reorder = sparse_conv_arrays.reorder\n",
    "    index = sparse_conv_arrays.index\n",
    "    stride = sparse_conv_arrays.stride\n",
    "    weight = sparse_conv_arrays.weight\n",
    "    ptset = sparse_conv_arrays.ptset\n",
    "    #print(f\"offset:{offset}\\n\\nreorder:{reorder}\\n\\nindex:{index}\\n\\nstride:{stride}\\n\\nweight:{weight}\\n\\nptset:\\n{ptset}\")\n",
    "    #print(conv_layer_weight)\n",
    "    ### Space\n",
    "    print('*'*10 + f' conv layer {idx} ' + '*'*10)\n",
    "    print(f'Normal_conv_mask:\\n{residual_convs[idx].nbytes}')\n",
    "    print(f'FKW_conv_mask:\\n{offset.nbytes+reorder.nbytes+index.nbytes+stride.nbytes+weight.nbytes+ptset.nbytes}\\n')\n",
    "    #print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "150bc54a-d770-4168-aeea-915e031e72f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.341818181818184"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "147456/6600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe6bac",
   "metadata": {},
   "source": [
    "### Time Cost w/o memory transfer - sparse_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43449230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005999040022492409\n",
      "0.0052144320085644735\n",
      "[0.00015772800147533417, 0.0001335040032863617, 0.00014745600521564483, 0.00012931199371814727, 0.0001446399986743927, 0.00013475200533866882, 0.00012166400253772736, 0.00013926400244235993, 0.0001566399931907654, 0.0001228799968957901, 0.00015568000078201294, 0.00012492799758911133, 0.000179967999458313, 0.0001433600038290024, 0.00014921599626541138, 0.0001470720022916794, 0.0002229440063238144, 0.0001536320000886917, 0.00024374400079250335, 0.00015836800634860994, 0.0002260800004005432, 0.00017369599640369417, 0.0002258239984512329, 0.0001842560023069382, 0.0001966399997472763, 0.0002396160066127777, 0.0002070080041885376, 0.00030649599432945254, 0.0003256320059299469, 0.0002825599908828735, 0.0003645760118961334, 0.00019990399479866028]\n",
      "[0.00013385599851608278, 0.00013046400249004366, 0.0001380160003900528, 0.00012086399644613266, 0.00015641599893569946, 0.00013836799561977388, 0.00011161600053310394, 0.00011846400052309037, 0.00012950399518013, 0.00011472000181674958, 0.0001452160030603409, 0.00011468800157308579, 0.00015113599598407746, 0.0001218239963054657, 0.0001188800036907196, 0.00011395200341939927, 0.0001802240014076233, 0.00011468800157308579, 0.0001969600021839142, 0.00012595200538635255, 0.00020073600113391878, 0.00013062399625778199, 0.00018809600174427032, 0.00014745600521564483, 0.0001661120057106018, 0.00020255999267101288, 0.0001770880073308945, 0.00027993598580360415, 0.0003070720136165619, 0.00023964799940586092, 0.0003382079899311066, 0.0001610880047082901]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from execution_time import SparseConvolution\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "conv = SparseConvolution()\n",
    "\n",
    "path = 'resnet34_6_pattern_connectivity_pruning.pt'\n",
    "state_dict = torch.load(path, map_location=torch.device('cpu'))\n",
    "\n",
    "residual_convs = [v.cpu().numpy() for (k, v) in state_dict.items() if \"layer\" in k and \"conv\" in k]\n",
    "data_shapes = [\n",
    "        [1, 64, 32, 32], [1, 64, 32, 32], [1, 64, 32, 32], [1, 64, 32, 32], [1, 64, 32, 32], [1, 64, 32, 32],\n",
    "        [1, 64, 32, 32], [1, 128, 16, 16], [1, 128, 16, 16], [1, 128, 16, 16], [1, 128, 16, 16], [1, 128, 16, 16],\n",
    "        [1, 128, 16, 16], [1, 128, 16, 16], [1, 128, 16, 16], [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8],\n",
    "        [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8],\n",
    "        [1, 256, 8, 8], [1, 256, 8, 8], [1, 256, 8, 8], [1, 512, 4, 4], [1, 512, 4, 4], [1, 512, 4, 4],\n",
    "        [1, 512, 4, 4], [1, 512, 4, 4]]\n",
    "\n",
    "time_without_mem_list_naive = []\n",
    "time_include_mem_list_naive = []\n",
    "time_without_mem_list_shared = []\n",
    "time_include_mem_list_shared = []\n",
    "time_without_mem_list_constant = []\n",
    "time_include_mem_list_constant = []\n",
    "\n",
    "time_wo_naive = 0\n",
    "time_wo_shared = 0\n",
    "time_wo_constant = 0\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(residual_convs[:]))):\n",
    "    input_data = np.float32(np.ones(data_shapes[i]))\n",
    "\n",
    "    if i == len(residual_convs) - 1:\n",
    "        output_data =  np.float32(np.zeros(data_shapes[i]))\n",
    "    else:\n",
    "        output_data =  np.float32(np.zeros(data_shapes[i + 1]))\n",
    "\n",
    "    conv_layer_weight = residual_convs[i].astype(np.float32)\n",
    "    patterns = np.array(extract_patterns(conv_layer_weight))\n",
    "    sparse_conv_arrays = SparseConvArrays(conv_layer_weight, patterns)\n",
    "    offset = sparse_conv_arrays.offset\n",
    "    reorder = sparse_conv_arrays.reorder\n",
    "    index = sparse_conv_arrays.index\n",
    "    stride = sparse_conv_arrays.stride\n",
    "    sparse_weight = sparse_conv_arrays.weight\n",
    "    ptset = np.float32(sparse_conv_arrays.ptset)\n",
    "\n",
    "    # step 卷积步长\n",
    "    if i == len(residual_convs) - 1:\n",
    "        step = 1\n",
    "    else:\n",
    "        step = int(data_shapes[i][2] / data_shapes[i + 1][2])\n",
    "        \n",
    "    output_naive, time_without_mem_naive, time_include_mem_naive = conv.conv_sparse_naive(input_data, offset, reorder, index, stride, sparse_weight, ptset, step, output_data)\n",
    "    output_shared, time_without_mem_shared, time_include_mem_shared = conv.conv_sparse_shared_mem(input_data, offset, reorder, index, stride, sparse_weight, ptset, step, output_data)\n",
    "\n",
    "    time_without_mem_list_naive.append(time_without_mem_naive)\n",
    "    time_include_mem_list_naive.append(time_include_mem_naive)\n",
    "    time_without_mem_list_shared.append(time_without_mem_shared)\n",
    "    time_include_mem_list_shared.append(time_include_mem_shared)\n",
    "    \n",
    "    time_wo_naive += time_without_mem_naive\n",
    "    time_wo_shared += time_without_mem_shared\n",
    "    \n",
    "\n",
    "        #constant memory limit\n",
    "    if sparse_weight.shape[0] <= 16384:\n",
    "        output_constant, time_without_mem_constant,  time_include_mem_constant = conv.conv_sparse_shared_constant_mem(input_data, offset, reorder, index, stride, sparse_weight, ptset, step, output_data)\n",
    "        time_without_mem_list_constant.append(time_without_mem_constant)\n",
    "        time_include_mem_list_constant.append(time_include_mem_constant)\n",
    "\n",
    "\n",
    "\n",
    "print(time_wo_naive)\n",
    "print(time_wo_shared)\n",
    "print(time_without_mem_list_naive)\n",
    "print(time_without_mem_list_shared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
